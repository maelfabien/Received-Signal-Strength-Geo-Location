{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-One-Device-Out and Publish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T20:26:36.930778Z",
     "start_time": "2019-01-09T20:26:34.711125Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy.distance import vincenty\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T20:26:43.016696Z",
     "start_time": "2019-01-09T20:26:36.935104Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/Users/maelfabien/Desktop/LocalDB/RSSI/df_mess_train_3.csv')\n",
    "df_test = pd.read_csv('/Users/maelfabien/Desktop/LocalDB/RSSI/df_mess_test_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T20:26:43.117148Z",
     "start_time": "2019-01-09T20:26:43.019595Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['Unnamed: 0'], axis=1)\n",
    "df_test = df_test.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T20:26:43.127307Z",
     "start_time": "2019-01-09T20:26:43.120592Z"
    }
   },
   "outputs": [],
   "source": [
    "def vincenty_vec(vec_coord):\n",
    "    vin_vec_dist = np.zeros(vec_coord.shape[0])\n",
    "    if vec_coord.shape[1] !=  4:\n",
    "        print('ERROR: Bad number of columns (shall be = 4)')\n",
    "    else:\n",
    "        vin_vec_dist = [vincenty(vec_coord[m,0:2],vec_coord[m,2:]).meters for m in range(vec_coord.shape[0])]\n",
    "    return vin_vec_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T20:26:43.142232Z",
     "start_time": "2019-01-09T20:26:43.131427Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate distance error for each predicted point\n",
    "def Eval_geoloc(y_train_lat , y_train_lng, y_pred_lat, y_pred_lng):\n",
    "    y_pred_lat[np.where(y_pred_lat>90)[0]]=90\n",
    "    y_pred_lat[np.where(y_pred_lat<-90)[0]]=-90\n",
    "    vec_coord = np.array([np.array(y_train_lat) , np.array(y_train_lng), y_pred_lat, y_pred_lng])\n",
    "    err_vec = vincenty_vec(np.transpose(vec_coord))\n",
    "    \n",
    "    return err_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T20:26:43.167479Z",
     "start_time": "2019-01-09T20:26:43.148012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 473335.,  473953.,  476512.,  476286.,  473438.,  476185.,\n",
       "        476285.,  476314.,  476306.,  476317.,  476320.,  473502.,\n",
       "        476318.,  476197.,  476312.,  476316.,  476251.,  476308.,\n",
       "        473683.,  473796.,  476323.,  476329.,  476321.,  476324.,\n",
       "        476332.,  476322.,  473864.,  473512.,  473805.,  476327.,\n",
       "        476325.,  476515.,  476505.,  476517.,  476212.,  476503.,\n",
       "        476507.,  476611.,  476610.,  476606.,  476604.,  476607.,\n",
       "        476602.,  476609.,  476600.,  476598.,  476615.,  476521.,\n",
       "        476525.,  476523.,  476830.,  474181.,  476828.,  474126.,\n",
       "        476826.,  476853.,  476315.,  474176.,  476852.,  476987.,\n",
       "        476307.,  476868.,  476833.,  476861.,  473897.,  476276.,\n",
       "        473902.,  476275.,  476888.,  476891.,  476274.,  476280.,\n",
       "        476257.,  476210.,  476231.,  474192.,  476225.,  476256.,\n",
       "        476161.,  476228.,  476835.,  473368.,  473892.,  476883.,\n",
       "        476889.,  476884.,  476887.,  473899.,  476885.,  476253.,\n",
       "        473871.,  476248., 1747448., 1747434.,  473401.,  476596.,\n",
       "        473507.,  477201.,  476829.,  477023.,  476567.,  476331.,\n",
       "        473288.,  476123.,  476140.,  476594.,  476896.,  476836.,\n",
       "        476513.,  476207.,  476841.,  476337.,  476593.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['did'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For independent risks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-09T20:26:39.162Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_independent = []\n",
    "\n",
    "for device in df_train['did'].unique() :\n",
    "    \n",
    "    df_train_lov = df_train[df_train.did != device]\n",
    "    df_test_lov = df_train[df_train.did == device]\n",
    "    \n",
    "    X_train = df_train_lov.drop(['messid', 'lat', 'lng', 'did'], axis=1)\n",
    "    y_lat_train = df_train_lov['lat']\n",
    "    y_lng_train = df_train_lov['lng']\n",
    "    \n",
    "    X_test = df_test_lov.drop(['messid', 'lat', 'lng', 'did'], axis=1)\n",
    "    y_lat_test = df_test_lov['lat']\n",
    "    y_lng_test = df_test_lov['lng']\n",
    "    \n",
    "    clf_lng = ExtraTreesRegressor(n_estimators=10)\n",
    "    clf_lng.fit(X_train, y_lng_train)\n",
    "    pred_lng = clf_lng.predict(X_test)\n",
    "    \n",
    "    clf_lat = ExtraTreesRegressor(n_estimators=10)\n",
    "    clf_lat.fit(X_train, y_lat_train)\n",
    "    pred_lat = clf_lat.predict(X_test)\n",
    "    \n",
    "    err_vec = Eval_geoloc(y_lat_test , y_lng_test, pred_lat, pred_lng)\n",
    "    err = np.percentile(err_vec, 80)\n",
    "    error_independent.append(err)\n",
    "    \n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For dependent risks, by predicting first the longitude :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-09T20:26:40.169Z"
    }
   },
   "outputs": [],
   "source": [
    "error_lng = []\n",
    "\n",
    "for device in df_train['did'].unique() :\n",
    "    \n",
    "    df_train_lov = df_train[df_train.did != device]\n",
    "    df_test_lov = df_train[df_train.did == device]\n",
    "    \n",
    "    X_train = df_train_lov.drop(['messid', 'lat', 'lng', 'did'], axis=1)\n",
    "    y_lat_train = df_train_lov['lat']\n",
    "    y_lng_train = df_train_lov['lng']\n",
    "    \n",
    "    X_test = df_test_lov.drop(['messid', 'lat', 'lng', 'did'], axis=1)\n",
    "    y_lat_test = df_test_lov['lat']\n",
    "    y_lng_test = df_test_lov['lng']\n",
    "    \n",
    "    clf_lng = ExtraTreesRegressor(n_estimators=10)\n",
    "    clf_lng.fit(X_train, y_lng_train)\n",
    "    pred_lng = clf_lng.predict(X_test)\n",
    "    \n",
    "    clf_lat = ExtraTreesRegressor(n_estimators=10)\n",
    "    new_X_train = pd.concat([X_train, y_lng_train], axis=1)\n",
    "    \n",
    "    clf_lat.fit(new_X_train, y_lat_train)\n",
    "    new_X = pd.concat([X_test.reset_index(drop=True), pd.DataFrame(pred_lng).reset_index(drop=True)], axis=1)\n",
    "    pred_lat = clf_lat.predict(new_X)\n",
    "    \n",
    "    err_vec = Eval_geoloc(y_lat_test , y_lng_test, pred_lat, pred_lng)\n",
    "    err = np.percentile(err_vec, 80)\n",
    "    error_lng.append(err)\n",
    "    \n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For dependent risks, by predicting first the latitude :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-09T20:26:43.577Z"
    }
   },
   "outputs": [],
   "source": [
    "error_lat = []\n",
    "\n",
    "for device in df_train['did'].unique() :\n",
    "    \n",
    "    df_train_lov = df_train[df_train.did != device]\n",
    "    df_test_lov = df_train[df_train.did == device]\n",
    "    \n",
    "    X_train = df_train_lov.drop(['messid', 'lat', 'lng', 'did'], axis=1)\n",
    "    y_lat_train = df_train_lov['lat']\n",
    "    y_lng_train = df_train_lov['lng']\n",
    "    \n",
    "    X_test = df_test_lov.drop(['messid', 'lat', 'lng', 'did'], axis=1)\n",
    "    y_lat_test = df_test_lov['lat']\n",
    "    y_lng_test = df_test_lov['lng']\n",
    "    \n",
    "    clf_lat = ExtraTreesRegressor(n_estimators=10)\n",
    "    clf_lat.fit(X_train, y_lat_train)\n",
    "    pred_lat = clf_lat.predict(X_test)\n",
    "    \n",
    "    clf_lng = ExtraTreesRegressor(n_estimators=10)\n",
    "    new_X_train = pd.concat([X_train, y_lat_train], axis=1)\n",
    "    \n",
    "    clf_lng.fit(new_X_train, y_lng_train)\n",
    "    new_X = pd.concat([X_test.reset_index(drop=True), pd.DataFrame(pred_lat).reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    pred_lng = clf_lng.predict(new_X)\n",
    "    \n",
    "    err_vec = Eval_geoloc(y_lat_test , y_lng_test, pred_lat, pred_lng)\n",
    "    err = np.percentile(err_vec, 80)\n",
    "    error_lat.append(err)\n",
    "    \n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-09T20:26:48.947Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Independant : \" + str(np.median(np.array(error_independent).mean())))\n",
    "print(\"Longitude First : \" + str(np.median(np.array(error_lng).mean())))\n",
    "print(\"Latitude First : \" + str(np.median(np.array(error_lat).mean())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model appears to be : Estimating longitude first, and then latitude in the dependent model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
